<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.122.0">


<title> - xiaohaoyang</title>
<meta property="og:title" content=" - xiaohaoyang">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/cv/">CV</a></li>
    
    <li><a href="https://github.com/billbillbilly">GitHub</a></li>
    
    <li><a href="/publications/">Publications</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title"></h1>

    

    <div class="article-content">
      
      <p>Coding art is fun. I got one self-motivated project (the first one) and several course-based projects.</p>
<h1 id="pop-upcolorhttpsbillbillbillygithubioportfolio-content"><a href="https://billbillbilly.github.io/portfolio-content/">Pop-upColor</a></h1>
<p><code>Pop-upColor</code> is an generative art project I started in 2021. Initially, I just played with celular autometa to create some interesting 3D patterns with Python in <a href="https://www.rhino3d.com/">Rhinoceros</a></p>
<hr>
<h1 id="yo-yocap">Yo-yoCap</h1>
<p><code>Yo-yoCap</code> explores the enhancement of yo-yo performance art through the application of motion capture technology, aiming to create a more dynamic and interactive audio-visual spectacle. By utilizing 2D motion capture with <a href="https://github.com/opencv/opencv">OpenCV</a> and transmitting data to <a href="https://cycling74.com/products/max">MAX/MSP</a> for processing, this research investigates how real-time tracking of yo-yo movements can alter background music and visualizations. The project involves analyzing key parameters such as yo-yo position and movement, and integrating these with an interactive system that responds to the performerâ€™s actions.</p>
<hr>
<h1 id="spank2skate-this-project-is-cool-and-could-be-cooler">spank2skate (This project is cool and could be cooler)</h1>
<p><code>spank2skate</code></p>
<hr>
<h1 id="fakevr-this-is-a-very-funny-project">fakeVR (This is a very funny project)</h1>
<p>VR (virtual reality) has been a useful visual tool for designers, especially architecture people, to present and experience their 3D environment during the prototyping process and presentation. The human-centered experience provided by VR can give people a relatively realistic sense of 3D space and an isolated environment to explore space. However, most VR presentation options require a high-performance headset or computer with a fancy graphic card. <code>fakeVR</code> tries to provide a low-fi VR option (simulated VR experience) only using smartphones (inertial motion tracking) for prototype purposes.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
  </body>
</html>

